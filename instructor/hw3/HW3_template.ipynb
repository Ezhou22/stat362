{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"HW3: Mixed Supervised + Unsupervised Tasks on the Zymo Mock Dataset\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The [ZymoBIOMICS mock microbial community](https://github.com/LomanLab/mockcommunity) is a standardized mixture of known bacterial and fungal taxa at defined proportions. Because the true composition is known, it is widely used as a benchmarking and proof-of-concept dataset for evaluating bioinformatics pipelines, feature representations, and ecological analysis methods.\n",
    "\n",
    "In this homework, you will use the Zymo mock community as a controlled testbed to assess the quality of **GenSLMs sequence embeddings**.\n",
    "\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "GenSLMs embeddings are pretrained representations derived from the **GenSLM foundation model** (GitHub: https://github.com/ramanathanlab/genslm).  \n",
    "They are intended to capture biologically meaningful patterns such as evolutionary or phylogenetic relatedness and shared functional motifs.\n",
    "\n",
    "There are 10 reference genomes in this dataset. Metagenomic reads have been assembled into contigs. The reference genome IDs correspond to:\n",
    "\n",
    "- **0**: *Bacillus subtilis*\n",
    "- **1**: *Cryptococcus neoformans*\n",
    "- **2**: *Enterococcus faecalis*\n",
    "- **3**: *Escherichia coli*\n",
    "- **4**: *Lactobacillus fermentum*\n",
    "- **5**: *Listeria monocytogenes*\n",
    "- **6**: *Pseudomonas aeruginosa*\n",
    "- **7**: *Saccharomyces cerevisiae*\n",
    "- **8**: *Salmonella enterica*\n",
    "- **9**: *Staphylococcus aureus*\n",
    "\n",
    "Among these genomes, **E. coli** and **Salmonella** share ~87.04% similarity, and **Bacillus** and **Staphylococcus** share ~72.25% similarity.\n",
    "\n",
    "\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "We hypothesize that GenSLMs embeddings encode evolutionary and functional signals strongly enough that:\n",
    "\n",
    "1. A classifier trained on the embeddings can accurately predict contig origin (genome ID).\n",
    "2. Low-dimensional projections (PCA / UMAP / t-SNE) reveal coherent clusters aligned with genome IDs, including known similarity pairs (e.g., *E. coli* vs. *Salmonella*).\n",
    "3. Clustering algorithms applied to the embeddings approximate true contig origin groupings with high homogeneity and completeness.\n",
    "\n",
    "\n",
    "\n",
    "### Strategy\n",
    "\n",
    "1. Load contig-level embeddings and genome IDs.\n",
    "2. Perform a stratified train/test split to evaluate generalization.\n",
    "3. Train multiple multi-class classifiers (Logistic Regression, LightGBM, XGBoost, CatBoost) and select the best model based on macro F1.\n",
    "4. To speed up classification, reduce the dimensionality using PCA and UMAP, and evaluate how different numbers of components affect classification performance.\n",
    "5. Visualize the embeddings using PCA, t-SNE, and UMAP with tuned hyperparameters; annotate notable overlaps (e.g., *E. coli* vs. *Salmonella*).\n",
    "6. Apply clustering (DBSCAN / HDBSCAN / KMeans) on the 2D reduced space and compute homogeneity and completeness scores.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "- **Classification**: macro precision, macro recall, macro F1, accuracy.\n",
    "- **Visualization**: qualitative cluster separation and overlapping\n",
    "- **Clustering**: homogeneity_score, completeness_score, number of clusters vs expected genomes, outlier count (if applicable).\n",
    "\n",
    "\n",
    "### Open-Ended Nature\n",
    "\n",
    "This assignment is intentionally open-ended — there is no single “correct” setting.  \n",
    "You are encouraged to explore reasonable hyperparameters.  \n",
    "For some steps, I also provide my own settings so that everyone starts from the same baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genslm_npz = np.load(\"zymo_genslm_embeddings.npz\")\n",
    "genslm_npz['e'].shape\n",
    "genslm_npz['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genslm_embed = pd.DataFrame(genslm_npz['e'])\n",
    "genslm_embed['rid'] = genslm_npz['id']\n",
    "genslm_embed=genslm_embed.sample(frac=1)\n",
    "genslm_embed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the value count of the rid\n",
    "genslm_embed['rid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into feature and target\n",
    "X = genslm_embed.iloc[:, :-1].values\n",
    "y = genslm_embed.iloc[:, -1].values\n",
    "\n",
    "# split the data into training and test set with stratify\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multi-Class Classification (20 points)\n",
    "\n",
    "Apply multiple classifiers to the dataset and identify the best-performing model based on the **macro F1 score**.  \n",
    "The classifiers to evaluate include: **Multinomial Logistic Regression, LightGBM, XGBoost, and CatBoost**.\n",
    "\n",
    "Please display the performance metrics for each classifier (e.g., **accuracy, macro precision, macro recall, macro F1**) to justify your selection of the top model for the downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Dimensionality Reduction for Efficient Classification (20 points)\n",
    "\n",
    "Using the full embedding dimensionality for classification can be computationally intensive.  \n",
    "In this step, your objective is to reduce the dimensionality of the data using **PCA** and **UMAP** to speed up classification.\n",
    "\n",
    "Explore multiple values of `n_components` to evaluate how dimensionality affects classification performance.  \n",
    "Use the **best-performing classifier identified in Task 1**.\n",
    "\n",
    "The dimensionalities to explore are:\n",
    "\n",
    "```python\n",
    "n_components = [10, 20, 43, 100, 150, 200, 300, 400]\n",
    "```\n",
    "\n",
    "For each setting, report the **accuracy, macro precision, macro recall, and macro F1 score**.\n",
    "\n",
    "After completing your experiments:\n",
    "\n",
    "- **Identify which dimensionality reduction method (PCA or UMAP) performs better overall on this dataset.**\n",
    "- **Determine the best-performing `n_components` value based on the evaluation metrics.**\n",
    "\n",
    "**Note:** t-SNE is mainly used for reducing data to 2 or 3 dimensions for visualization.  \n",
    "Because it does not scale effectively to higher-dimensional embeddings, we **exclude it** from this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Visualizing High-Dimensional Embeddings Using PCA, t-SNE, and UMAP (20 points)\n",
    "\n",
    "Visualize the high-dimensional data using **PCA**, **t-SNE**, and **UMAP**.  \n",
    "Keep in mind that tuning the hyperparameters for t-SNE and UMAP is essential for producing informative plots.\n",
    "\n",
    "Experiment with different settings to generate the most insightful visualizations, and **explicitly report the best hyperparameters you identified through your experiments** in your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Evaluating Clustering Algorithms on 2D Embeddings (30 points)\n",
    "\n",
    "Clustering algorithms often struggle with the curse of dimensionality, which can lead to poor performance on high-dimensional data.  \n",
    "To address this, use the **2-dimensional representation** obtained from **t-SNE** in Task 2 (`n_components = 2`, `perplexity = 25`).\n",
    "\n",
    "Apply **three different clustering algorithms** to the 2D data and evaluate their effectiveness.  \n",
    "For each algorithm, report the following:\n",
    "\n",
    "- **Visualization** of the clustering result (dimension = 2)\n",
    "- **Number of clusters**\n",
    "- **Number of outliers** (`cluster_labels == -1`, if applicable)\n",
    "- **Completeness score** and **Homogeneity score**  \n",
    "  (refer to scikit-learn documentation for how to compute these metrics given ground-truth labels)\n",
    "\n",
    "**Note:**  \n",
    "Since clustering is unsupervised, use the entire dataset when tuning hyperparameters (no train-test split needed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Summary of Best Results and Reflection (10 points)\n",
    "\n",
    "Summarize the best results you obtained from each of the previous tasks and explain what you learned from this assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
